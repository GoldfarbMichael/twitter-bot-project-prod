{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-06-11T16:13:50.399468Z",
     "start_time": "2025-06-11T16:13:50.379383Z"
    }
   },
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict\n",
    "import requests\n",
    "import time\n",
    "from sklearn.decomposition import PCA\n",
    "from umap import UMAP\n",
    "import hdbscan\n"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Text cleaning #",
   "id": "ee89765e652d36fe"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T16:13:53.433905Z",
     "start_time": "2025-06-11T16:13:53.419350Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_tweet(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"http\\S+|www.\\S+\", \"\", text)  # URLs\n",
    "    text = re.sub(r\"@\\w+|#\\w+\", \"\", text)        # mentions/hashtags\n",
    "    text = re.sub(r\"[^\\w\\s]\", \"\", text)          # punctuation\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text if len(text.split()) >= 5 else None\n"
   ],
   "id": "2ca3c78362fef2b0",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T16:14:24.629760Z",
     "start_time": "2025-06-11T16:13:57.933119Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../data/bot_tweets_by_user.csv\")\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_tweet)\n",
    "df = df.dropna(subset=[\"clean_text\"])"
   ],
   "id": "46c62c00c8f1e02",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T09:18:47.289031Z",
     "start_time": "2025-06-11T09:04:20.384218Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = SentenceTransformer(\"all-MiniLM-L6-v2\", device=\"cuda\")\n",
    "\n",
    "batch_size = 256\n",
    "embeddings = []\n",
    "texts = df[\"clean_text\"].tolist()\n",
    "\n",
    "for i in tqdm(range(0, len(texts), batch_size)):\n",
    "    batch = texts[i:i + batch_size]\n",
    "    with torch.no_grad():\n",
    "        emb = model.encode(batch, show_progress_bar=False)\n",
    "    embeddings.extend(emb)\n",
    "\n",
    "# Optionally save\n",
    "np.save(\"model_data/tweet_embeddings.npy\", embeddings)"
   ],
   "id": "aadbcb5a4b941b8",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3173/3173 [14:20<00:00,  3.69it/s]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Clustering Topics #",
   "id": "f9223a8a72a515dd"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-11T18:51:22.638774Z",
     "start_time": "2025-06-11T18:50:59.171437Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.read_csv(\"../data/bot_tweets_by_user.csv\")\n",
    "df[\"clean_text\"] = df[\"text\"].apply(clean_tweet)\n",
    "df = df.dropna(subset=[\"clean_text\"])\n",
    "texts = df[\"clean_text\"].tolist()"
   ],
   "id": "8827e3fe83791581",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "embeddings = np.load(\"model_data/tweet_embeddings.npy\")\n",
    "\n",
    "pca = PCA(n_components=50)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "umap_model = UMAP(\n",
    "    n_neighbors=5,\n",
    "    n_components=5,\n",
    "    metric=\"cosine\",\n",
    "    n_epochs=200,\n",
    "    low_memory=True,\n",
    "    n_jobs=-1,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "umap_embeddings = umap_model.fit_transform(reduced_embeddings)\n",
    "hdbscan_model = hdbscan.HDBSCAN(\n",
    "    min_cluster_size=30,\n",
    "    metric=\"euclidean\",\n",
    "    prediction_data=True\n",
    ")\n",
    "\n",
    "cluster_labels = hdbscan_model.fit_predict(umap_embeddings)\n",
    "np.save(\"model_data/umap_embeddings.npy\", umap_embeddings)\n",
    "np.save(\"model_data/cluster_labels.npy\", cluster_labels)"
   ],
   "id": "9f1d2685e3f30dfa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Test Clustering #",
   "id": "14883c0af8dafdb6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T06:49:51.588409Z",
     "start_time": "2025-06-12T06:49:51.437952Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df_clusters = pd.DataFrame({\n",
    "    \"text\": texts,\n",
    "    \"cluster\": cluster_labels\n",
    "})\n",
    "\n",
    "# Example: Count of texts per cluster\n",
    "cluster_counts = df_clusters[\"cluster\"].value_counts()\n",
    "print(cluster_counts)\n",
    "\n",
    "# Example: Show sample texts from a specific cluster (e.g., cluster 0)\n",
    "print(df_clusters[df_clusters[\"cluster\"] == 5908].head())"
   ],
   "id": "d45f5d2bf656a7a7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cluster\n",
      "-1       314670\n",
      " 4154     12408\n",
      " 772       3018\n",
      " 5908      2315\n",
      " 3436      2185\n",
      "          ...  \n",
      " 3994        30\n",
      " 7179        30\n",
      " 5051        30\n",
      " 6107        30\n",
      " 6516        30\n",
      "Name: count, Length: 7229, dtype: int64\n",
      "                                                   text  cluster\n",
      "1617          war until the death of the last ukrainian     5908\n",
      "1713  situation militaire en ukraine au 14 janvier 2...     5908\n",
      "3242  2 so i was thinking about this whole war in uk...     5908\n",
      "3261  2 so i was thinking about this whole war in uk...     5908\n",
      "4078  heres an interesting analysis on by an author ...     5908\n"
     ]
    }
   ],
   "execution_count": 30
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Labeling Clusters with LLM #\n",
    "* using Together.ai API to label clusters based on sampled tweets\n",
    "* requires an API key from Together.ai as an user input\n",
    "* LLM model: Mistral-7B-Instruct-v0.2"
   ],
   "id": "a5557dbc1dce9ed"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T10:02:23.852153Z",
     "start_time": "2025-06-12T08:50:31.778377Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Group tweets by cluster\n",
    "cluster_to_texts = defaultdict(list)\n",
    "for text, label in zip(texts, cluster_labels):\n",
    "    if label != -1:\n",
    "        cluster_to_texts[label].append(text)\n",
    "\n",
    "# Sampling function\n",
    "def sample_cluster(cluster_texts, max_samples=20):\n",
    "    if len(cluster_texts) <= max_samples:\n",
    "        return cluster_texts\n",
    "    return random.sample(cluster_texts, max_samples)\n",
    "\n",
    "# Together.ai config\n",
    "TOGETHER_API_KEY = input(\"Enter your Together API key: \").strip()\n",
    "TOGETHER_MODEL = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "TOGETHER_MODEL = \"mistralai/Mistral-7B-Instruct-v0.2\"\n",
    "\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {TOGETHER_API_KEY}\",\n",
    "    \"Content-Type\": \"application/json\"\n",
    "}\n",
    "\n",
    "# LLM request function\n",
    "def label_cluster(cluster_texts):\n",
    "    sample = \"\\n\".join(cluster_texts)\n",
    "    prompt = (\n",
    "        f\"Here are some tweets from the same topic:\\n\\n{sample}\\n\\n\"\n",
    "        \"Please summarize this topic in 3-5 keywords or short phrases that best describe it:\"\n",
    "    )\n",
    "\n",
    "    data = {\n",
    "        \"model\": TOGETHER_MODEL,\n",
    "        \"prompt\": prompt,\n",
    "        \"max_tokens\": 50,\n",
    "        \"temperature\": 0.2,\n",
    "        \"stop\": None\n",
    "    }\n",
    "\n",
    "    for attempt in range(5):\n",
    "        response = requests.post(\"https://api.together.xyz/v1/completions\", headers=headers, json=data)\n",
    "        if response.status_code == 200:\n",
    "            return response.json()[\"choices\"][0][\"text\"].strip()\n",
    "        else:\n",
    "            print(f\"Error {response.status_code}, retrying...\")\n",
    "            time.sleep(2)  # Retry delay\n",
    "\n",
    "    return \"[LLM_ERROR]\"\n",
    "\n",
    "# Full batch loop\n",
    "cluster_labels_dict = {}\n",
    "\n",
    "for cluster_id, texts_in_cluster in tqdm(cluster_to_texts.items(), desc=\"Labeling clusters\"):\n",
    "    sampled_texts = sample_cluster(texts_in_cluster, max_samples=20)\n",
    "    topic_label = label_cluster(sampled_texts)\n",
    "    cluster_labels_dict[cluster_id] = topic_label\n",
    "\n",
    "# Save topics\n",
    "labels_df = pd.DataFrame.from_dict(cluster_labels_dict, orient='index', columns=['topic_label'])\n",
    "labels_df.index.name = 'cluster_id'\n",
    "labels_df.to_csv(\"model_data/llm_topic_labels.csv\")\n",
    "\n",
    "# Merge with original dataset (optional)\n",
    "df_full = pd.DataFrame({\n",
    "    'text': texts,\n",
    "    'cluster_id': cluster_labels\n",
    "})\n",
    "df_full = df_full.merge(labels_df, how='left', on='cluster_id')\n",
    "df_full.to_csv(\"../data/labeled_tweets.csv\", index=False)\n"
   ],
   "id": "1e8c97ac6a99112a",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6509/7228 [1:02:57<08:09,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6510/7228 [1:03:00<15:54,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6513/7228 [1:03:09<22:15,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6518/7228 [1:03:17<13:24,  1.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6520/7228 [1:03:24<26:04,  2.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6522/7228 [1:03:28<22:34,  1.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6524/7228 [1:03:36<31:07,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6525/7228 [1:03:39<32:35,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6526/7228 [1:03:50<1:02:27,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6527/7228 [1:03:56<1:01:46,  5.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6528/7228 [1:04:07<1:24:46,  7.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6529/7228 [1:04:15<1:26:50,  7.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6530/7228 [1:04:18<1:10:28,  6.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6531/7228 [1:04:29<1:28:17,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6532/7228 [1:04:41<1:43:35,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6533/7228 [1:04:53<1:52:09,  9.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6534/7228 [1:04:55<1:27:54,  7.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6535/7228 [1:04:58<1:11:08,  6.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n",
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6537/7228 [1:05:04<49:36,  4.31s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  90%|█████████ | 6541/7228 [1:05:09<19:47,  1.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  91%|█████████ | 6542/7228 [1:05:12<23:31,  2.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  91%|█████████ | 6559/7228 [1:05:23<05:58,  1.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters:  91%|█████████ | 6561/7228 [1:05:27<12:02,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error 402, retrying...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Labeling clusters: 100%|██████████| 7228/7228 [1:11:47<00:00,  1.68it/s]\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-12T10:36:16.919857Z",
     "start_time": "2025-06-12T10:36:16.904823Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(df_full.head())\n",
    "\n",
    "print(\"\\n\\n\\n\",labels_df.head)\n",
    "print(\"\\n\",labels_df.shape)"
   ],
   "id": "3b80a1b913e4cd2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  cluster_id  \\\n",
      "0  they traded her freedom for a real supervillai...          -1   \n",
      "1  its not the weapons its avoiding the sanctions...        5673   \n",
      "2  its not the weapons its avoiding the sanctions...        5673   \n",
      "3  they traded her freedom for a real supervillai...          -1   \n",
      "4  sacrificio estremo degli ucraini attacchi suic...        4154   \n",
      "\n",
      "                                         topic_label  \n",
      "0                                                NaN  \n",
      "1  * Iran Sanctions\\n* Human Rights Violations\\n*...  \n",
      "2  * Iran Sanctions\\n* Human Rights Violations\\n*...  \n",
      "3                                                NaN  \n",
      "4  1. Russia-Ukraine War\\n2. Vladimir Putin\\n3. X...  \n",
      "\n",
      "\n",
      "\n",
      " <bound method NDFrame.head of                                                   topic_label\n",
      "cluster_id                                                   \n",
      "5673        * Iran Sanctions\\n* Human Rights Violations\\n*...\n",
      "4154        1. Russia-Ukraine War\\n2. Vladimir Putin\\n3. X...\n",
      "2658        * Vladimir Karamurza\\n* Sentenced to 25 years ...\n",
      "3180        1. Everyday life\\n2. Positivity\\n3. Small mome...\n",
      "4553        * Warm weather destinations\\n* Australian mona...\n",
      "...                                                       ...\n",
      "662         * Fenerbahce vs Kayserispor\\n* Live Streaming\\...\n",
      "663         * Liverpool vs Corinthians\\n* Live Streaming\\n...\n",
      "439         * Coin Master\\n* Free Spins\\n* Retweet\\n* Comm...\n",
      "6396        1. Claim Spins Now\\n2. Twitter Promotion\\n3. O...\n",
      "1131        * Massage in Khobar\\n* Hotel\\n* Download free\\...\n",
      "\n",
      "[7228 rows x 1 columns]>\n",
      "\n",
      " (7228, 1)\n"
     ]
    }
   ],
   "execution_count": 41
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
